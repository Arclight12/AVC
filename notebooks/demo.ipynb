{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Biosignal to Phoneme Conversion Demo\n",
                "\n",
                "This notebook demonstrates the training and inference of two models for converting biosignals to phonemes:\n",
                "1. **UniGRU + CTC**: The baseline model.\n",
                "2. **Transformer**: An Encoder-Decoder attention-based model.\n",
                "\n",
                "The code has been refactored into modular Python files for better maintainability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add project root to path\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "from src.dataset import SyntheticDataset, MAX_SEQUENCE_LENGTH\n",
                "from src.models.gru import SensorToPhonemeGRU\n",
                "from src.models.transformer import SensorToPhonemeTransformer\n",
                "from src.utils import INDEX_TO_PH, greedy_decode, FEATURE_DIM, SOS_INDEX, NUM_PHONEMES\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Train UniGRU + CTC Model\n",
                "We will run the training script `src/train.py` as a module."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run from project root\n",
                "import os\n",
                "os.chdir('..') # Go to project root\n",
                "!python -m src.train --model_type gru --epochs 5 --num_samples 1000"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train Transformer Model\n",
                "Now we train the Transformer model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m src.train --model_type transformer --epochs 5 --num_samples 1000"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Inference\n",
                "Let's load the trained models and run inference on a sample sentence."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper to generate a sample\n",
                "ds = SyntheticDataset(num_samples=1)\n",
                "sample_idx = 0\n",
                "X, Y, L, L_target = ds[sample_idx]\n",
                "\n",
                "# Prepare input\n",
                "X_tensor = X.unsqueeze(0).to(device) # (1, T, F)\n",
                "input_len = torch.tensor([L], dtype=torch.long).to(device)\n",
                "\n",
                "print(\"Ground Truth:\", [INDEX_TO_PH.get(int(y), \"?\") for y in Y])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### UniGRU Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_gru = SensorToPhonemeGRU().to(device)\n",
                "try:\n",
                "    model_gru.load_state_dict(torch.load(\"model_gru.pth\"))\n",
                "    model_gru.eval()\n",
                "    with torch.no_grad():\n",
                "        logp = model_gru(X_tensor)\n",
                "        input_len_reduced = (input_len // 4).clamp(min=1)\n",
                "        decoded = greedy_decode(logp, input_len_reduced)[0]\n",
                "        print(\"UniGRU Prediction:\", decoded)\n",
                "except FileNotFoundError:\n",
                "    print(\"Model file not found. Please run training first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Transformer Inference\n",
                "For Transformer, we need to autoregressively generate the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_tf = SensorToPhonemeTransformer().to(device)\n",
                "try:\n",
                "    model_tf.load_state_dict(torch.load(\"model_transformer.pth\"))\n",
                "    model_tf.eval()\n",
                "    \n",
                "    # Autoregressive decoding\n",
                "    # Start with <SOS>\n",
                "    decoder_input = torch.tensor([[SOS_INDEX]], dtype=torch.long).to(device)\n",
                "    \n",
                "    pred_seq = []\n",
                "    max_len = 50\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for _ in range(max_len):\n",
                "            # Create masks if needed (not strictly necessary for inference one step at a time if we just pass full seq)\n",
                "            # But nn.Transformer expects full sequence so far\n",
                "            tgt_mask = model_tf.generate_square_subsequent_mask(decoder_input.size(1)).to(device)\n",
                "            \n",
                "            output = model_tf(X_tensor, decoder_input, tgt_mask=tgt_mask)\n",
                "            \n",
                "            # Get last token prediction\n",
                "            last_token_logits = output[:, -1, :] # (B, C)\n",
                "            next_token = last_token_logits.argmax(dim=-1).item()\n",
                "            \n",
                "            if next_token == SOS_INDEX: # Should not happen usually\n",
                "                continue\n",
                "                \n",
                "            pred_seq.append(INDEX_TO_PH.get(next_token, \"?\"))\n",
                "            \n",
                "            # Append to input\n",
                "            decoder_input = torch.cat([decoder_input, torch.tensor([[next_token]], device=device)], dim=1)\n",
                "            \n",
                "            # Stop condition (if we had EOS, but we didn't train with EOS explicitly in the loop above for simplicity)\n",
                "            # But let's stop if length matches roughly\n",
                "            \n",
                "    print(\"Transformer Prediction:\", pred_seq)\n",
                "    \n",
                "except FileNotFoundError:\n",
                "    print(\"Model file not found. Please run training first.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}